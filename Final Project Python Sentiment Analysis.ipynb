{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You must install the tweepy package before using it!\n",
    "\n",
    "import tweepy\n",
    "import numpy as np\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save your consumer key, consumer secret, access token, and access secret here.\n",
    "# Don't share these secrets with others!  If you're building code for Twitter which many people will share,\n",
    "# you should encrypt this information.  \n",
    "# It's also possible to generate access tokens and secrets from within an app.\n",
    "\n",
    "#con_key = 'Insert your key here'\n",
    "#con_secret = 'insert your secret here'\n",
    "#acc_token = 'insert your token here'\n",
    "#acc_secret = 'insert your secret here'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#aetna-twitter search\n",
    "#Connect to the Twitter API using the authentication\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "csvFile = open('aetna_cleaned.csv', 'a')\n",
    "\n",
    "#Use csv writer\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "for tweet in tweepy.Cursor(api.search,\n",
    "                           q = \"aetna\",\n",
    "                           since = \"2017-04-01\",\n",
    "                           until = \"2017-04-15\",\n",
    "                           lang = \"en\").items():\n",
    "    analysis = TextBlob(tweet.text)\n",
    "    # Write a row to the CSV file. I use encode UTF-8\n",
    "    csvWriter.writerow([tweet.created_at, tweet.text.encode('utf-8'),analysis.sentiment.polarity,analysis.sentiment.subjectivity])\n",
    "csvFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Obamacare-twitter search\n",
    "#Connect to the Twitter API using the authentication\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "csvFile = open('obamacare_result.csv', 'a')\n",
    "\n",
    "#Use csv writer\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "for tweet in tweepy.Cursor(api.search,\n",
    "                           q = \"obamacare\",\n",
    "                           since = \"2017-04-01\",\n",
    "                           until = \"2017-04-15\",\n",
    "                           lang = \"en\").items():\n",
    "    analysis = TextBlob(tweet.text)\n",
    "    # Write a row to the CSV file. I use encode UTF-8\n",
    "    csvWriter.writerow([tweet.created_at, tweet.text.encode('utf-8'),analysis.sentiment.polarity,analysis.sentiment.subjectivity])\n",
    "csvFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#single payer\n",
    "auth = tweepy.OAuthHandler(consumer_key=con_key, consumer_secret=con_secret)\n",
    "auth.set_access_token(acc_token, acc_secret)\n",
    "\n",
    "#Connect to the Twitter API using the authentication\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#public_tweets = api.search('aetna',language ='en',count = 1000)\n",
    "\n",
    "csvFile = open('singlePayerTwoWordQuery.csv', 'a')\n",
    "\n",
    "#Use csv writer\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "for tweet in tweepy.Cursor(api.search,\n",
    "                           q = \"\\\"single payer\\\"\",#the \"\\ cyntax forces the phrase 'single payer' to be searched \n",
    "                           since = \"2017-02-01\",\n",
    "                           until = \"2017-04-15\",\n",
    "                           lang = \"en\").items():\n",
    "    analysis = TextBlob(tweet.text)\n",
    "    # Write a row to the CSV file. I use encode UTF-8\n",
    "    csvWriter.writerow([tweet.created_at, tweet.text.encode('utf-8'),analysis.sentiment])\n",
    "csvFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false

   "source": [
    "#anthem twitter search\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "csvFile = open('anthem_insurance_result.csv', 'a')\n",
    "\n",
    "#Use csv writer\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "for tweet in tweepy.Cursor(api.search,\n",
    "                           q = \"anthem insurance\",\n",
    "                           since = \"2017-04-01\",\n",
    "                           until = \"2017-04-15\",\n",
    "                           lang = \"en\").items():\n",
    "    analysis = TextBlob(tweet.text)\n",
    "    # Write a row to the CSV file. I use encode UTF-8\n",
    "    csvWriter.writerow([tweet.created_at, tweet.text.encode('utf-8'),analysis.sentiment.polarity,analysis.sentiment.subjectivity])\n",
    "csvFile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#united health twitter search\n",
    "csvFile = open('united_results.csv', 'a')\n",
    "\n",
    "#Use csv writer\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "for tweet in tweepy.Cursor(api.search,\n",
    "                           q = \"\\\"united health\\\"\",#the \"\\ cyntax forces the phrase 'united health' to be searched and not a combination of the words united and health\n",
    "                           since = \"2017-02-01\",\n",
    "                           until = \"2017-04-23\",\n",
    "                           lang = \"en\").items():\n",
    "    analysis = TextBlob(tweet.text)\n",
    "    # Write a row to the CSV file. I use encode UTF-8\n",
    "    csvWriter.writerow([tweet.created_at, tweet.text.encode('utf-8'),analysis.sentiment.polarity,analysis.sentiment.subjectivity])\n",
    "csvFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#homework\n",
    "\"auth = tweepy.OAuthHandler(consumer_key=con_key, consumer_secret=con_secret)\n",
    "auth.set_access_token(acc_token, acc_secret)\n",
    "\n",
    "#Connect to the Twitter API using the authentication\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "csvFile = open('homework.csv', 'a')\n",
    "\n",
    "#Use csv writer\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "for tweet in tweepy.Cursor(api.search,\n",
    "                           q = \"homework\",\n",
    "                           since = \"2017-04-01\",\n",
    "                           until = \"2017-04-15\",\n",
    "                           lang = \"en\").items():\n",
    "    analysis = TextBlob(tweet.text)\n",
    "    # Write a row to the CSV file. I use encode UTF-8\n",
    "    csvWriter.writerow([tweet.created_at, tweet.text.encode('utf-8'),analysis.sentiment.polarity,analysis.sentiment.subjectivity])\n",
    "csvFile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cussLength(x):\n",
    "    #cussLenth is a custum function to find the number of tweets with cusswords in a dataframe\n",
    "    #input = dataframe\n",
    "    #output = length of dataframe of tweets containing cusswords\n",
    "    #the following line creates a new df with text containing the cuss words\n",
    "    cussTweets= x[x['text'].str.contains(\"fuck|hate|shit|damn|fucking|damned|horseshit|ass|crap|bastard|fuckers|motherfuckers|bitch|prick\")==True]\n",
    "    value = len(cussTweets)\n",
    "    return value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mean polarity of Single Payer tweets is 0.16323790405851715\n",
      "the mean subjectivity of Single Payer tweets is 0.4212714338877766\n",
      "the number of cussy SP tweets are 237\n"
     ]
    }
   ],
   "source": [
    "#analyze singlePayer results\n",
    "import csv\n",
    "import pandas as pd\n",
    "dfSP=pd.read_csv('C:/Users/sawitri.schultz/Google Drive/Grad School/710 Assignments from Dropbox/FinalProject/singlePayerTwoWordQuery.csv')\n",
    "dfSP = dfSP[pd.notnull(dfSP['text'])] #remove null rows\n",
    "SPPolMean = dfSP['polarity'].mean()\n",
    "SPSubMean = dfSP['subjectivity'].mean()\n",
    "\n",
    "\n",
    "print(\"the mean polarity of Single Payer tweets is \"+ str(SPPolMean))\n",
    "print(\"the mean subjectivity of Single Payer tweets is \"+ str(SPSubMean))\n",
    "cussSPTweets=cussLength(dfSP)\n",
    "print (\"the number of cussy SP tweets are \"+ str(cussSPTweets))\n",
    "\n",
    "#write cleaned df to csv\n",
    "dfSP.to_csv('singlePayerFromPython.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mean polarity of Aetna tweets is 0.046202352870850796\n",
      "the mean subjectivity of Aetna tweets is 0.2631886217103195\n",
      "the number of cussy aetna tweets are 55\n"
     ]
    }
   ],
   "source": [
    "#aetna analysis\n",
    "dfAetna=pd.read_csv('C:/Users/sawitri.schultz/Google Drive/Grad School/710 Assignments from Dropbox/FinalProject/aetna_cleaned.csv')\n",
    "dfAetna = dfAetna[pd.notnull(dfAetna['text'])] #remove null rows\n",
    "aetnaPolMean = dfAetna['polarity'].mean()\n",
    "aetnaSubMean = dfAetna['subjectivity'].mean()\n",
    "print(\"the mean polarity of Aetna tweets is \"+ str(aetnaPolMean))\n",
    "print(\"the mean subjectivity of Aetna tweets is \"+ str(aetnaSubMean))\n",
    "\n",
    "cussAetnaTweets=cussLength(dfAetna)\n",
    "print (\"the number of cussy aetna tweets are \"+ str(cussAetnaTweets))\n",
    "#write cleaned df to csv\n",
    "dfAetna.to_csv('aetnaFromPython.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mean polarity of Anthem tweets is 0.03710127585850991\n",
      "the mean subjectivity of Anthem tweets is 0.1720152654941899\n",
      "the number of cussy Anthem tweets are 2\n"
     ]
    }
   ],
   "source": [
    "#anthem analysis\n",
    "dfAnthem=pd.read_csv('C:/Users/sawitri.schultz/Google Drive/Grad School/710 Assignments from Dropbox/FinalProject/anthem_insurance_result.csv')\n",
    "dfAnthem = dfAnthem[pd.notnull(dfAnthem['text'])] #remove null rows\n",
    "anthemPolMean = dfAnthem['polarity'].mean()\n",
    "anthemSubMean = dfAnthem['subjectivity'].mean()\n",
    "print(\"the mean polarity of Anthem tweets is \"+ str(anthemPolMean))\n",
    "print(\"the mean subjectivity of Anthem tweets is \"+ str(anthemSubMean))\n",
    "cussAnthemTweets=cussLength(dfAnthem)\n",
    "print (\"the number of cussy Anthem tweets are \"+ str(cussAnthemTweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mean polarity of obamacare tweets is 0.021047746829113884\n",
      "the mean subjectivity of obamacare tweets is 0.25310989476507834\n",
      "the number of cussy obamacare tweets are 88\n"
     ]
    }
   ],
   "source": [
    "#obamacare Analysis\n",
    "dfObamacare=pd.read_csv('C:/Users/sawitri.schultz/Google Drive/Grad School/710 Assignments from Dropbox/FinalProject/obamacare_result.csv')\n",
    "dfObamacare = dfObamacare[pd.notnull(dfObamacare['text'])] #remove null rows\n",
    "obamacarePolMean = dfObamacare['polarity'].mean()\n",
    "obamacareSubMean = dfObamacare['subjectivity'].mean()\n",
    "print(\"the mean polarity of obamacare tweets is \"+ str(obamacarePolMean))\n",
    "print(\"the mean subjectivity of obamacare tweets is \"+ str(obamacareSubMean))\n",
    "cussObamacareTweets = cussLength(dfObamacare)\n",
    "\n",
    "print (\"the number of cussy obamacare tweets are \"+ str(cussObamacareTweets))\n",
    "#write cleaned df to csv\n",
    "dfObamacare.to_csv('obamacareFromPython.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mean polarity of cigna tweets is 0.1204940833985628\n",
      "the mean subjectivity of cigna tweets is 0.26335604163792153\n",
      "the number of cussy cigna tweets are 41\n"
     ]
    }
   ],
   "source": [
    "#cigna Analysis\n",
    "dfCigna=pd.read_csv('C:/Users/sawitri.schultz/Google Drive/Grad School/710 Assignments from Dropbox/FinalProject/cigna_result.csv')\n",
    "dfCigna = dfCigna[pd.notnull(dfCigna['text'])] #remove null rows\n",
    "cignaPolMean = dfCigna['polarity'].mean()\n",
    "cignaSubMean = dfCigna['subjectivity'].mean()\n",
    "print(\"the mean polarity of cigna tweets is \"+ str(cignaPolMean))\n",
    "print(\"the mean subjectivity of cigna tweets is \"+ str(cignaSubMean))\n",
    "cussCignaTweets = cussLength(dfCigna)\n",
    "print (\"the number of cussy cigna tweets are \"+ str(cussCignaTweets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mean polarity of united tweets is -0.08421192881333349\n",
      "the mean subjectivity of united tweets is 0.3690117364106672\n",
      "the number of cussy united tweets is 4\n"
     ]
    }
   ],
   "source": [
    "#united health Analysis\n",
    "dfUnited=pd.read_csv('C:/Users/sawitri.schultz/Google Drive/Grad School/710 Assignments from Dropbox/FinalProject/united_results.csv')\n",
    "dfUnited = dfUnited[pd.notnull(dfUnited['text'])] #remove null rows\n",
    "unitedPolMean = dfUnited['polarity'].mean()\n",
    "unitedSubMean = dfUnited['subjectivity'].mean()\n",
    "\n",
    "print(\"the mean polarity of united tweets is \"+ str(unitedPolMean))\n",
    "print(\"the mean subjectivity of united tweets is \"+ str(unitedSubMean))\n",
    "\n",
    "cussUnitedTweets = cussLength(dfUnited)\n",
    "print (\"the number of cussy united tweets is \"+ str(cussUnitedTweets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mean polarity of trump tweets is 0.07380151371295599\n",
      "the mean subjectivity of trump tweets is 0.291717698874534\n",
      "the number of cussy homework tweets are 286\n"
     ]
    }
   ],
   "source": [
    "#homework Analysis\n",
    "dfHomework=pd.read_csv('C:/Users/sawitri.schultz/Google Drive/Grad School/710 Assignments from Dropbox/ds710spring2017finalproject/homework.csv')\n",
    "dfHomework = dfHomework[pd.notnull(dfHomework['text'])] #remove null rows\n",
    "HomeworkMean = dfHomework['polarity '].mean()\n",
    "subjectMean = dfHomework['subjectivity'].mean()\n",
    "print(\"the mean polarity of trump tweets is \"+ str(HomeworkMean))\n",
    "print(\"the mean subjectivity of trump tweets is \"+ str(subjectMean))\n",
    "\n",
    "cussHomeworkTweets = cussLength(dfHomework)\n",
    "print (\"the number of cussy homework tweets are \"+ str(cussHomeworkTweets))\n",
    "#dfHomework \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mean polarity of trump tweets is 0.0039552407377543355\n",
      "the mean subjectivity of trump tweets is 0.3152318066186885\n",
      "the number of cussy trump tweets are 114\n"
     ]
    }
   ],
   "source": [
    "#trump Analysis\n",
    "dfTrump=pd.read_csv('C:/Users/sawitri.schultz/Google Drive/Grad School/710 Assignments from Dropbox/ds710spring2017finalproject/trump_results.csv')\n",
    "\n",
    "dfTrump = dfTrump[pd.notnull(dfTrump['text'])] #remove null rows\n",
    "TrumpPolMean = dfTrump['polarity'].mean()\n",
    "TrumpSubMean = dfTrump['subjectivity'].mean()\n",
    "\n",
    "\n",
    "print(\"the mean polarity of trump tweets is \"+ str(TrumpPolMean))\n",
    "print(\"the mean subjectivity of trump tweets is \"+ str(TrumpSubMean))\n",
    "cussTrumpTweets = cussLength(dfTrump)\n",
    "print (\"the number of cussy trump tweets are \"+ str(cussTrumpTweets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
